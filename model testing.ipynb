{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e913f1bf",
   "metadata": {},
   "source": [
    " <span style=\"color: purple; font-weight: bold; font-size:26px\"> Check if any models performs better than the naive classifier </span>\n",
    "\n",
    "\n",
    "Let's start by importing some libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72e7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# visualisations\n",
    "import seaborn \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "import pickle # for saving the model\n",
    "\n",
    "# preprocesing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# just out of curiosity\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52001656",
   "metadata": {},
   "source": [
    "Now, let's define some helper functions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9265a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define some helper functions:\n",
    "\n",
    "def plot_models_acc(dict, naive_classifier):\n",
    "    labels = tuple(dict.keys())\n",
    "    y_pos = np.arange(len(labels))\n",
    "    values = [dict[n]['accuracy'] for n in dict]\n",
    "    plt.bar(y_pos, values, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, labels,rotation='vertical')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy of different models')\n",
    "    # add a horizontal line at naive_classfier\n",
    "    plt.axhline(y=naive_classifier, color='r', linestyle='-', label='Naive Classifier')\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# checking the distribution of the features :)\n",
    "def feature_dist(dataframe):\n",
    "    col_num = len(dataframe.columns)\n",
    "    from_to_ind = [(i, i+6) for i in range(0, col_num, 6)]\n",
    "\n",
    "    for i, j in from_to_ind:\n",
    "        if j >= col_num:\n",
    "            if col_num - 1 == i:\n",
    "                dataframe.iloc[:, i].hist(figsize=(11,11))\n",
    "            else:\n",
    "                dataframe.iloc[:, i:col_num-1].hist(layout=(1,col_num - 1 - i), figsize=(11,11))\n",
    "        else:\n",
    "            dataframe.iloc[:, i:j].hist(layout=(2,3), figsize=(11,11))\n",
    "            \n",
    "            \n",
    "def conf_mat(grid_search: GridSearchCV, Y_test):\n",
    "    # construction confusion matrix\n",
    "    outcome_class_labels = ['Red', 'Draw', 'No contest', 'Blue']\n",
    "    cm = confusion_matrix(\n",
    "        Y_test, \n",
    "        grid_search.predict(X_test),\n",
    "        labels = outcome_class_labels\n",
    "    )\n",
    "\n",
    "    # create heatmap\n",
    "    seaborn.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        cmap='Blues', \n",
    "        xticklabels=outcome_class_labels,\n",
    "        yticklabels=outcome_class_labels,\n",
    "        fmt='d')\n",
    "\n",
    "    # add labels\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b51020",
   "metadata": {},
   "source": [
    "### Importing data\n",
    "Let's import our data now. It will most likely change, since the older data seems to be a little weird. For example, most of the winners are on the red side, most of some data is missing etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8385526",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"./UFCdata/datasets/UFC_complete_merged.xlsx\")\n",
    "data = data.sort_values('Event_Date', ascending=True).reset_index(drop=True)\n",
    "data = data.replace(['--', '---'], pd.NA)[2400:] \n",
    "# also just for now, but starting from 3000's row is a nice tradeoff\n",
    "# between a lower naive classifier accuracy and the completeness of the data\n",
    "\n",
    "# alternatively:\n",
    "# 3000 0.5640214216163584\n",
    "# 2400 0.5677570093457944\n",
    "# 1300 0.5728305785123967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deec5a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4708 entries, 2400 to 7107\n",
      "Columns: 226 entries, Unnamed: 0.1 to B_Total_Significant_Strikes_on_Ground_Landed\n",
      "dtypes: bool(1), datetime64[ns](1), float64(182), int64(29), object(13)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc83d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>R_Height_cm</th>\n",
       "      <th>R_Weight_kg</th>\n",
       "      <th>R_Reach</th>\n",
       "      <th>R_Age</th>\n",
       "      <th>R_Average_Knockdowns</th>\n",
       "      <th>R_Average_Significant_Strikes_Attempted</th>\n",
       "      <th>R_Average_Significant_Strikes_Landed</th>\n",
       "      <th>...</th>\n",
       "      <th>B_Total_Significant_Strikes_on_Body_Attempted</th>\n",
       "      <th>B_Total_Significant_Strikes_on_Body_Landed</th>\n",
       "      <th>B_Total_Significant_Strikes_on_Leg_Attempted</th>\n",
       "      <th>B_Total_Significant_Strikes_on_Leg_Landed</th>\n",
       "      <th>B_Total_Significant_Strikes_at_Distance_Attempted</th>\n",
       "      <th>B_Total_Significant_Strikes_at_Distance_Landed</th>\n",
       "      <th>B_Total_Significant_Strikes_in_Clinch_Attempted</th>\n",
       "      <th>B_Total_Significant_Strikes_in_Clinch_Landed</th>\n",
       "      <th>B_Total_Significant_Strikes_on_Ground_Attempted</th>\n",
       "      <th>B_Total_Significant_Strikes_on_Ground_Landed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4708.000000</td>\n",
       "      <td>4708.000000</td>\n",
       "      <td>4708.000000</td>\n",
       "      <td>4708.000000</td>\n",
       "      <td>4708.000000</td>\n",
       "      <td>4624.000000</td>\n",
       "      <td>4708.000000</td>\n",
       "      <td>4708.000000</td>\n",
       "      <td>4708.000000</td>\n",
       "      <td>4708.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "      <td>4649.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3612.097281</td>\n",
       "      <td>3612.097281</td>\n",
       "      <td>3612.097281</td>\n",
       "      <td>177.486007</td>\n",
       "      <td>73.803937</td>\n",
       "      <td>182.092842</td>\n",
       "      <td>30.937128</td>\n",
       "      <td>0.239183</td>\n",
       "      <td>80.829807</td>\n",
       "      <td>36.052094</td>\n",
       "      <td>...</td>\n",
       "      <td>55.493439</td>\n",
       "      <td>38.120456</td>\n",
       "      <td>36.712196</td>\n",
       "      <td>29.491934</td>\n",
       "      <td>347.559045</td>\n",
       "      <td>134.778232</td>\n",
       "      <td>40.574102</td>\n",
       "      <td>28.143902</td>\n",
       "      <td>41.047967</td>\n",
       "      <td>28.254463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2022.513871</td>\n",
       "      <td>2022.513871</td>\n",
       "      <td>2022.513871</td>\n",
       "      <td>9.244279</td>\n",
       "      <td>16.030511</td>\n",
       "      <td>11.308305</td>\n",
       "      <td>4.246129</td>\n",
       "      <td>0.297608</td>\n",
       "      <td>47.929491</td>\n",
       "      <td>21.297735</td>\n",
       "      <td>...</td>\n",
       "      <td>76.705121</td>\n",
       "      <td>53.215970</td>\n",
       "      <td>55.687494</td>\n",
       "      <td>44.686853</td>\n",
       "      <td>461.181088</td>\n",
       "      <td>183.923457</td>\n",
       "      <td>57.322420</td>\n",
       "      <td>40.459024</td>\n",
       "      <td>62.134152</td>\n",
       "      <td>42.453027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>152.400000</td>\n",
       "      <td>52.154195</td>\n",
       "      <td>147.320000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1900.750000</td>\n",
       "      <td>1900.750000</td>\n",
       "      <td>1900.750000</td>\n",
       "      <td>170.180000</td>\n",
       "      <td>61.224490</td>\n",
       "      <td>175.260000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3580.500000</td>\n",
       "      <td>3580.500000</td>\n",
       "      <td>3580.500000</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>70.294785</td>\n",
       "      <td>182.880000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>78.324561</td>\n",
       "      <td>34.763889</td>\n",
       "      <td>...</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5392.250000</td>\n",
       "      <td>5392.250000</td>\n",
       "      <td>5392.250000</td>\n",
       "      <td>185.420000</td>\n",
       "      <td>83.900227</td>\n",
       "      <td>190.500000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>109.297619</td>\n",
       "      <td>48.426901</td>\n",
       "      <td>...</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7096.000000</td>\n",
       "      <td>7096.000000</td>\n",
       "      <td>7096.000000</td>\n",
       "      <td>210.820000</td>\n",
       "      <td>120.181406</td>\n",
       "      <td>213.360000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>5490.000000</td>\n",
       "      <td>2454.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>442.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1      Column1   Unnamed: 0  R_Height_cm  R_Weight_kg  \\\n",
       "count   4708.000000  4708.000000  4708.000000  4708.000000  4708.000000   \n",
       "mean    3612.097281  3612.097281  3612.097281   177.486007    73.803937   \n",
       "std     2022.513871  2022.513871  2022.513871     9.244279    16.030511   \n",
       "min       31.000000    31.000000    31.000000   152.400000    52.154195   \n",
       "25%     1900.750000  1900.750000  1900.750000   170.180000    61.224490   \n",
       "50%     3580.500000  3580.500000  3580.500000   177.800000    70.294785   \n",
       "75%     5392.250000  5392.250000  5392.250000   185.420000    83.900227   \n",
       "max     7096.000000  7096.000000  7096.000000   210.820000   120.181406   \n",
       "\n",
       "           R_Reach        R_Age  R_Average_Knockdowns  \\\n",
       "count  4624.000000  4708.000000           4708.000000   \n",
       "mean    182.092842    30.937128              0.239183   \n",
       "std      11.308305     4.246129              0.297608   \n",
       "min     147.320000    18.000000              0.000000   \n",
       "25%     175.260000    28.000000              0.000000   \n",
       "50%     182.880000    31.000000              0.166667   \n",
       "75%     190.500000    34.000000              0.363636   \n",
       "max     213.360000    46.000000              3.000000   \n",
       "\n",
       "       R_Average_Significant_Strikes_Attempted  \\\n",
       "count                              4708.000000   \n",
       "mean                                 80.829807   \n",
       "std                                  47.929491   \n",
       "min                                   0.000000   \n",
       "25%                                  49.000000   \n",
       "50%                                  78.324561   \n",
       "75%                                 109.297619   \n",
       "max                                 367.000000   \n",
       "\n",
       "       R_Average_Significant_Strikes_Landed  ...  \\\n",
       "count                           4708.000000  ...   \n",
       "mean                              36.052094  ...   \n",
       "std                               21.297735  ...   \n",
       "min                                0.000000  ...   \n",
       "25%                               22.333333  ...   \n",
       "50%                               34.763889  ...   \n",
       "75%                               48.426901  ...   \n",
       "max                              189.000000  ...   \n",
       "\n",
       "       B_Total_Significant_Strikes_on_Body_Attempted  \\\n",
       "count                                    4649.000000   \n",
       "mean                                       55.493439   \n",
       "std                                        76.705121   \n",
       "min                                         0.000000   \n",
       "25%                                         4.000000   \n",
       "50%                                        29.000000   \n",
       "75%                                        75.000000   \n",
       "max                                       857.000000   \n",
       "\n",
       "       B_Total_Significant_Strikes_on_Body_Landed  \\\n",
       "count                                 4649.000000   \n",
       "mean                                    38.120456   \n",
       "std                                     53.215970   \n",
       "min                                      0.000000   \n",
       "25%                                      3.000000   \n",
       "50%                                     20.000000   \n",
       "75%                                     52.000000   \n",
       "max                                    639.000000   \n",
       "\n",
       "       B_Total_Significant_Strikes_on_Leg_Attempted  \\\n",
       "count                                   4649.000000   \n",
       "mean                                      36.712196   \n",
       "std                                       55.687494   \n",
       "min                                        0.000000   \n",
       "25%                                        2.000000   \n",
       "50%                                       16.000000   \n",
       "75%                                       48.000000   \n",
       "max                                      610.000000   \n",
       "\n",
       "       B_Total_Significant_Strikes_on_Leg_Landed  \\\n",
       "count                                4649.000000   \n",
       "mean                                   29.491934   \n",
       "std                                    44.686853   \n",
       "min                                     0.000000   \n",
       "25%                                     1.000000   \n",
       "50%                                    13.000000   \n",
       "75%                                    39.000000   \n",
       "max                                   494.000000   \n",
       "\n",
       "       B_Total_Significant_Strikes_at_Distance_Attempted  \\\n",
       "count                                        4649.000000   \n",
       "mean                                          347.559045   \n",
       "std                                           461.181088   \n",
       "min                                             0.000000   \n",
       "25%                                            26.000000   \n",
       "50%                                           192.000000   \n",
       "75%                                           470.000000   \n",
       "max                                          5490.000000   \n",
       "\n",
       "       B_Total_Significant_Strikes_at_Distance_Landed  \\\n",
       "count                                     4649.000000   \n",
       "mean                                       134.778232   \n",
       "std                                        183.923457   \n",
       "min                                          0.000000   \n",
       "25%                                          9.000000   \n",
       "50%                                         74.000000   \n",
       "75%                                        180.000000   \n",
       "max                                       2454.000000   \n",
       "\n",
       "       B_Total_Significant_Strikes_in_Clinch_Attempted  \\\n",
       "count                                      4649.000000   \n",
       "mean                                         40.574102   \n",
       "std                                          57.322420   \n",
       "min                                           0.000000   \n",
       "25%                                           1.000000   \n",
       "50%                                          19.000000   \n",
       "75%                                          54.000000   \n",
       "max                                         464.000000   \n",
       "\n",
       "       B_Total_Significant_Strikes_in_Clinch_Landed  \\\n",
       "count                                   4649.000000   \n",
       "mean                                      28.143902   \n",
       "std                                       40.459024   \n",
       "min                                        0.000000   \n",
       "25%                                        1.000000   \n",
       "50%                                       13.000000   \n",
       "75%                                       37.000000   \n",
       "max                                      330.000000   \n",
       "\n",
       "       B_Total_Significant_Strikes_on_Ground_Attempted  \\\n",
       "count                                      4649.000000   \n",
       "mean                                         41.047967   \n",
       "std                                          62.134152   \n",
       "min                                           0.000000   \n",
       "25%                                           0.000000   \n",
       "50%                                          16.000000   \n",
       "75%                                          56.000000   \n",
       "max                                         630.000000   \n",
       "\n",
       "       B_Total_Significant_Strikes_on_Ground_Landed  \n",
       "count                                   4649.000000  \n",
       "mean                                      28.254463  \n",
       "std                                       42.453027  \n",
       "min                                        0.000000  \n",
       "25%                                        0.000000  \n",
       "50%                                       12.000000  \n",
       "75%                                       39.000000  \n",
       "max                                      442.000000  \n",
       "\n",
       "[8 rows x 211 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d10e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc9aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb14d1",
   "metadata": {},
   "source": [
    "### Naive classifier\n",
    "\n",
    "The naive classifier that would be the least we should beat is the proportion of Red Winners to all fights outcomes, since it's the most common result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e565ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The naive classifier accuracy is:  0.5677570093457944\n"
     ]
    }
   ],
   "source": [
    "naive_classifier = data.loc[data['Winner'] == 'Red']['Winner'].count() / data['Winner'].count()\n",
    "print(\"The naive classifier accuracy is: \", naive_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fffa9d3",
   "metadata": {},
   "source": [
    "It will be quite hard to beat, hence it explains the need to re-run the scraper to obtain more recent data about the fights, since the naive classifier will drop significantly to a little bit over 56%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4598442b",
   "metadata": {},
   "source": [
    "We further need to drop some of the columns that will not be of use. I'll also remove closing odds since these will surely improve the model accuracy, but we shouldn't rely on them too much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "277d58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdata = data.drop(['Column1',\n",
    "                      'Unnamed: 0',\n",
    "                      'Unnamed: 0.1',\n",
    "                      'Event_Name',\n",
    "                      'Event_Location',\n",
    "                      'B_Name',\n",
    "                      'R_Name',\n",
    "                      'Conclusion_Method',\n",
    "                      'Event_Date',\n",
    "                      'Last_Round_Duration',\n",
    "                      'Number_of_Rounds',\n",
    "                      'Referee',\n",
    "                      'R_Closing_Odds', # bye bye closing odds...\n",
    "                      'B_Closing_Odds'], axis=1)\n",
    "\n",
    "# droping rows with 'Open Stance' since it's so seldom (but shouldn't be present for 2400 row onward)\n",
    "dropdata = dropdata.drop(dropdata[dropdata['R_Stance'] == 'Open Stance'].index)\n",
    "dropdata = dropdata.drop(dropdata[dropdata['B_Stance'] == 'Open Stance'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473eaaa2",
   "metadata": {},
   "source": [
    "Next, let's find numerical and categorical columns in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6704eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "objecttypes_cat = list(dropdata.select_dtypes(include=['O']).columns)\n",
    "objecttypes_num = list(dropdata.select_dtypes(include=['int64', 'float64']).columns)\n",
    "\n",
    "# we don't want to one-hot encode 'Winner' since it's not really required\n",
    "# and the pipeline braeks if we do (it'll be looking for this var in \n",
    "# X_train&X_test but it's obviously not there)\n",
    "objecttypes_cat = [x for x in objecttypes_cat if x != 'Winner']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ed5c3",
   "metadata": {},
   "source": [
    "## Data correlation\n",
    "\n",
    "Since we are givem a considerate number of features, instead of presenting all possible correlations, we'll stick to N most significant ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15db33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Subset Correlation Matrix\n",
    "# k = 10 #number of variables for heatmap\n",
    "# corrmat = dropdata.corr()\n",
    "# cols = corrmat.nlargest(k, 'Winner')['Winner'].index\n",
    "# cm = np.corrcoef(dropdata[cols].values.T)\n",
    "# seaborn.set(font_scale=1.25)\n",
    "# hm = seaborn.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1231426",
   "metadata": {},
   "source": [
    "# Candidate models\n",
    "\n",
    "We've chosen the following candidate models that we will further try to get the best performance from. In the end, we will present a comparison of each model.\n",
    "\n",
    "#### - Perceptron\n",
    "#### - Random Forests\n",
    "#### - Decision Trees Classifier\n",
    "#### - SGD Classifier\n",
    "#### - Linear SVC\n",
    "#### - Gaussian Naive Bayes\n",
    "#### - KNN\n",
    "\n",
    "PS.\n",
    "Models can be loaded after they are saved. However, pay attention when loading them up after the kernel restart - loaded model will make predictions based on different training set. This means that it was partially trained on the current test set. It is due to the shuffling we make during train_test splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "830d651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_models = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0187d88",
   "metadata": {},
   "source": [
    "### Standardizing the data (based on X_train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14bce0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed\n",
    "random.seed(2137)\n",
    "np.random.seed(2137)\n",
    "\n",
    "Y_all = dropdata['Winner']\n",
    "X_all = dropdata.drop(['Winner'], axis=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=0.25, random_state=2023)\n",
    "\n",
    "# standardizer for numerical columns\n",
    "transformer_num = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# standardizer for categorical columns\n",
    "transformer_cat = Pipeline([\n",
    "    ('scaler', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# jumping into using these into the preprocessor for all features:\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', transformer_num, objecttypes_num),\n",
    "        ('cat', transformer_cat, objecttypes_cat)   # no 'Winner' encoded\n",
    "], remainder='passthrough')\n",
    "\n",
    "# the standardization should be based on the training set, hence we obtain the relevant parameters:\n",
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78a89b0",
   "metadata": {},
   "source": [
    "## Perceptron:\n",
    "\n",
    "The Perceptron is another simple classification algorithm suitable for large scale learning. By default:\n",
    "\n",
    "        It does not require a learning rate.\n",
    "\n",
    "        It is not regularized (penalized).\n",
    "\n",
    "        It updates its model only on mistakes.\n",
    "\n",
    "The last characteristic implies that the Perceptron is slightly faster to train than SGD with the hinge loss and that the resulting models are sparser.\n",
    "\n",
    "- Linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fe529a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1680 candidates, totalling 8400 fits\n",
      "Accuracy on the test set:  0.47068819031435855\n",
      "\n",
      "Best parameters after the grid search:  {'model__alpha': 0.01, 'model__max_iter': 500, 'model__penalty': 'l1', 'model__tol': 0.001, 'selector__k': 50}\n",
      "\n",
      "Time taken for model to learn:  3234.0117008686066  seconds\n"
     ]
    }
   ],
   "source": [
    "# starting the timer to see how much time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# Let's define the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', KNNImputer()),\n",
    "    ('selector', SelectKBest()),\n",
    "    ('model', Perceptron(random_state=2023))\n",
    "])\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'selector__k': [10, 20, 30, 40, 50, 60, len(preprocessor.get_feature_names_out())],\n",
    "    'model__penalty': ['elasticnet', 'l2', 'l1', None],\n",
    "    'model__alpha': [0.01, 0.001, 0.0001, 0.00001],\n",
    "    'model__max_iter': [500, 1000, 1500],\n",
    "    'model__tol': [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "}\n",
    "\n",
    "# create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=3, verbose=2)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate the best model on the test set\n",
    "score = grid_search.score(X_test, Y_test)\n",
    "\n",
    "# stopping the timer and seeing the result: ------------------------\n",
    "end_time = time.time()\n",
    "\n",
    "print('Accuracy on the test set: ', score)\n",
    "print('\\nBest parameters after the grid search: ', grid_search.best_params_)\n",
    "print(\"\\nTime taken for model to learn: \", end_time - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2015954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "if input('Are you sure you want to run this cell? It will overwrite current best model. Y/N: ') == 'Y':\n",
    "    with open('trained_models/best_perceptron_model.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82fecf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters after the grid search:  {'model__alpha': 0.001, 'model__max_iter': 50, 'model__penalty': 'elasticnet', 'model__tol': 0.1, 'selector__k': 40}\n"
     ]
    }
   ],
   "source": [
    "# load the best model from disk using pickle\n",
    "with open('trained_models/best_perceptron_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print('Best parameters after the grid search: ', model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270af42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the selected feature indices after SelectKBest() in the best estimator\n",
    "selected_feature_indices = model.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = preprocessor.get_feature_names_out()[selected_feature_indices]\n",
    "print('Columns after feature selection: ', selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271356a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing accuracy score:\n",
    "acc_sco = accuracy_score(Y_test, model.predict(X_test)) \n",
    "\n",
    "# storing accuracy score:\n",
    "acc_sco = accuracy_score(Y_test, model.predict(X_test)) \n",
    "\n",
    "# construction confusion matrix\n",
    "cm = conf_mat(model, Y_test)\n",
    "\n",
    "# store model results in tuned_models dictionary\n",
    "\n",
    "print('Accuracy on the test set: ',acc_sco)\n",
    "tuned_models['Perceptron'] = {'accuracy': acc_sco, 'model': model, 'confusion_matrix': cm}\n",
    "\n",
    "# store model results in tuned_models dictionary\n",
    "\n",
    "tuned_models['Perceptron'] = {'accuracy': acc_sco, 'model': model, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e6f4b",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "A random forest classifier.\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd91b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    }
   ],
   "source": [
    "# starting the timer to see how much time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# Let's define the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', KNNImputer()),\n",
    "    ('selector', SelectKBest()),\n",
    "    ('model', RandomForestClassifier(random_state=2023))\n",
    "])\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'selector__k': [5, 15, 35, 60, 90, 120, 150, len(preprocessor.get_feature_names_out())],\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__criterion': ['gini'],\n",
    "    'model__max_depth': [None],\n",
    "    'model__min_samples_split': [2, 4, 6],\n",
    "    'model__min_samples_leaf': [1, 2],\n",
    "    'model__max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=2, n_jobs=4)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate the best model on the test set\n",
    "score = grid_search.score(X_test, Y_test)\n",
    "\n",
    "# stopping the timer and seeing the result: ------------------------\n",
    "end_time = time.time()\n",
    "\n",
    "print('Accuracy on the test set: ', score)\n",
    "print('\\nBest parameters after the grid search: ', grid_search.best_params_)\n",
    "print(\"\\nTime taken for model to learn: \", end_time - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "030b0c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure you want to run this cell? It will overwrite current best model. Y/N: Y\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk using pickle\n",
    "if input('Are you sure you want to run this cell? It will overwrite current best model. Y/N: ') == 'Y':\n",
    "    with open('trained_models/best_random_forest_model.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39135fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters after the grid search:  {'model__criterion': 'gini', 'model__max_depth': None, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 1, 'model__min_samples_split': 4, 'model__n_estimators': 200, 'selector__k': 90}\n"
     ]
    }
   ],
   "source": [
    "# load the best model from disk using pickle\n",
    "with open('trained_models/best_random_forest_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    " \n",
    "print('Best parameters after the grid search: ', model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56ff01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the selected feature indices after SelectKBest() in the best estimator\n",
    "selected_feature_indices = model.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = preprocessor.get_feature_names_out()[selected_feature_indices]\n",
    "print('\\nColumns after feature selection: ', selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c31307e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set:  0.6355140186915887\n"
     ]
    }
   ],
   "source": [
    "# storing accuracy score:\n",
    "acc_sco = accuracy_score(Y_test, model.predict(X_test)) \n",
    "\n",
    "# construction confusion matrix\n",
    "cm = conf_mat(model, Y_test)\n",
    "\n",
    "# store model results in tuned_models dictionary\n",
    "\n",
    "print('Accuracy on the test set: ', acc_sco)\n",
    "tuned_models['Random_Forest'] = {'accuracy': acc_sco, 'model': model, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a470cb",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "A decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac988d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the timer to see how much time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# Let's define the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('Imputer', KNNImputer()),\n",
    "    ('selector', SelectKBest()),\n",
    "    ('model', DecisionTreeClassifier(random_state=2023))\n",
    "])\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'selector__k': [3, 4, 5, 10, 15, 30],\n",
    "    'model__criterion': ['entropy'],\n",
    "    'model__max_depth': [2, 4, 6, 8, 10],\n",
    "    'model__min_samples_split': [2, 4, 6, 8],\n",
    "    'model__min_samples_leaf': [1, 2, 4, 8],\n",
    "    'model__max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=2, n_jobs=3)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate the best model on the test set\n",
    "score = grid_search.score(X_test, Y_test)\n",
    "\n",
    "# stopping the timer and seeing the result: ------------------------\n",
    "end_time = time.time()\n",
    "\n",
    "print('Accuracy on the test set: ', score)\n",
    "print('\\nBest parameters after the grid search: ', grid_search.best_params_)\n",
    "print(\"\\nTime taken for model to learn: \", end_time - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "if input('Are you sure you want to run this cell? It will overwrite current best model. Y/N: ') == 'Y':\n",
    "    with open('trained_models/best_decision_tree_model.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59407bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the best model from disk using pickle\n",
    "with open('trained_models/best_decision_tree_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    " \n",
    "print('Best parameters after the grid search: ', model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected feature indices after SelectKBest() in the best estimator\n",
    "selected_feature_indices = model.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = preprocessor.get_feature_names_out()[selected_feature_indices]\n",
    "print('Columns after feature selection: ', selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6158544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing accuracy score:\n",
    "acc_sco = accuracy_score(Y_test, model.predict(X_test)) \n",
    "\n",
    "# construction confusion matrix\n",
    "cm = conf_mat(model, Y_test)\n",
    "\n",
    "# store model results in tuned_models dictionary\n",
    "\n",
    "print('Accuracy on the test set: ',acc_sco)\n",
    "tuned_models['Decision_Tree'] = {'accuracy': acc_sco, 'model': model, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618658fb",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD) Classifier\n",
    "\n",
    "A linear classifier with SGD training. Default implementation uses the loss='hinge' used for linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010cc4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the timer to see how much time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# Let's define the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', KNNImputer()),\n",
    "    ('selector', SelectKBest()),\n",
    "    ('model', SGDClassifier(random_state=2023))\n",
    "])\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'selector__k': [30, 50, 70, 80, 90],\n",
    "    'model__alpha': [1, 0.1, 0.01],\n",
    "    'model__penalty': ['l1','l2', 'elasticnet'],\n",
    "    'model__max_iter': [200, 500],\n",
    "    'model__tol': [0.01, 0.001]\n",
    "}\n",
    "# create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=2, n_jobs=3)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate the best model on the test set\n",
    "score = grid_search.score(X_test, Y_test)\n",
    "\n",
    "# stopping the timer and seeing the result: ------------------------\n",
    "end_time = time.time()\n",
    "\n",
    "print('Accuracy on the test set: ', score)\n",
    "print('\\nBest parameters after the grid search: ', grid_search.best_params_)\n",
    "print(\"\\nTime taken for model to learn: \", end_time - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac519529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "if input('Are you sure you want to run this cell? It will overwrite current best model. Y/N: ') == 'Y':\n",
    "    with open('trained_models/best_SGDClassfier_model.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7007ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model from disk using pickle\n",
    "with open('trained_models/best_SGDClassfier_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    " \n",
    "print('Best parameters after the grid search: ', model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65087ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the selected feature indices after SelectKBest() in the best estimator\n",
    "selected_feature_indices = model.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = preprocessor.get_feature_names_out()[selected_feature_indices]\n",
    "print('Columns after feature selection: ', selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db22164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing accuracy score:\n",
    "acc_sco = accuracy_score(Y_test, model.predict(X_test)) \n",
    "\n",
    "# construction confusion matrix\n",
    "cm = conf_mat(model, Y_test)\n",
    "\n",
    "# store model results in tuned_models dictionary\n",
    "\n",
    "print('Accuracy on the test set: ',acc_sco)\n",
    "tuned_models['SGDClassfier'] = {'accuracy': acc_sco, 'model': model, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c8a93",
   "metadata": {},
   "source": [
    "## Linear SVC\n",
    "\n",
    "Linear Support Vector Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad8ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# starting the timer to see how much time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# Let's define the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', KNNImputer()),\n",
    "    #('selector', SelectKBest()),\n",
    "    ('model', LinearSVC(random_state=2023))\n",
    "])\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    #'selector__k': [40, 60, 70, 80],\n",
    "    'model__loss': ['hinge'],\n",
    "    'model__C': [0.001],\n",
    "    'model__penalty': ['l2'],\n",
    "    'model__max_iter': [100],\n",
    "    'model__tol': [0.001]\n",
    "}\n",
    "# create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=2, n_jobs=3)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate the best model on the test set\n",
    "score = grid_search.score(X_test, Y_test)\n",
    "\n",
    "# stopping the timer and seeing the result: ------------------------\n",
    "end_time = time.time()\n",
    "\n",
    "print('Accuracy on the test set: ', score)\n",
    "print('\\nBest parameters after the grid search: ', grid_search.best_params_)\n",
    "print(\"\\nTime taken for model to learn: \", end_time - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ab1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "if input('Are you sure you want to run this cell? It will overwrite current best model. Y/N: ') == 'Y':\n",
    "    with open('trained_models/best_LinearSVC_model.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671309ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model from disk using pickle\n",
    "with open('trained_models/best_LinearSVC_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    " \n",
    "print('Best parameters after the grid search: ', model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected feature indices after SelectKBest() in the best estimator\n",
    "selected_feature_indices = model.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = preprocessor.get_feature_names_out()[selected_feature_indices]\n",
    "print('Columns after feature selection: ', selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d7fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing accuracy score:\n",
    "acc_sco = accuracy_score(Y_test, model.predict(X_test)) \n",
    "\n",
    "# construction confusion matrix\n",
    "cm = conf_mat(model, Y_test)\n",
    "\n",
    "# store model results in tuned_models dictionary\n",
    "\n",
    "print('Accuracy on the test set: ',acc_sco)\n",
    "tuned_models['LinearSVC'] = {'accuracy': acc_sco, 'model': model, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45dac8f",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "Gaussian Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the timer to see how much time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# Let's define the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', KNNImputer()),\n",
    "    ('selector', SelectKBest()),\n",
    "    ('model', GaussianNB())\n",
    "])\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'selector__k': [1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 220],\n",
    "}\n",
    "# create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate the best model on the test set\n",
    "score = grid_search.score(X_test, Y_test)\n",
    "\n",
    "# stopping the timer and seeing the result: ------------------------\n",
    "end_time = time.time()\n",
    "\n",
    "print('Accuracy on the test set: ', score)\n",
    "print('\\nBest parameters after the grid search: ', grid_search.best_params_)\n",
    "print(\"\\nTime taken for model to learn: \", end_time - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "if input('Are you sure you want to run this cell? It will overwrite current best model. Y/N: ') == 'Y':\n",
    "    with open('trained_models/best_GaussianNB_model.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b8a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model from disk using pickle\n",
    "with open('trained_models/best_GaussianNB_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    " \n",
    "print('Best parameters after the grid search: ', model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a7b42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the selected feature indices after SelectKBest() in the best estimator\n",
    "selected_feature_indices = model.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = preprocessor.get_feature_names_out()[selected_feature_indices]\n",
    "print('Columns after feature selection: ', selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing accuracy score:\n",
    "acc_sco = accuracy_score(Y_test, model.predict(X_test)) \n",
    "\n",
    "# construction confusion matrix\n",
    "cm = conf_mat(model, Y_test)\n",
    "\n",
    "# store model results in tuned_models dictionary\n",
    "\n",
    "print('Accuracy on the test set: ',acc_sco)\n",
    "tuned_models['Gaussian_NB'] = {'accuracy': acc_sco, 'model': model, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437eed00",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "Classifier implementing the k-nearest neighbors vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the timer to see how much time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# Let's define the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', KNNImputer()),\n",
    "    #('selector', SelectKBest()),\n",
    "    ('model', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    #'selector__k': [5, 10, 20, 40, 60],\n",
    "    'model__n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "# create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate the best model on the test set\n",
    "score = grid_search.score(X_test, Y_test)\n",
    "\n",
    "# stopping the timer and seeing the result: ------------------------\n",
    "end_time = time.time()\n",
    "\n",
    "print('Accuracy on the test set: ', score)\n",
    "print('\\nBest parameters after the grid search: ', grid_search.best_params_)\n",
    "print(\"\\nTime taken for model to learn: \", end_time - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "if input('Are you sure you want to run this cell? It will overwrite current best model. Y/N: ') == 'Y':\n",
    "    with open('trained_models/best_KNN_model.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d444799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model from disk using pickle\n",
    "with open('trained_models/best_KNN_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    " \n",
    "print('Best parameters after the grid search: ', model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05280429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected feature indices after SelectKBest() in the best estimator\n",
    "selected_feature_indices = model.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = preprocessor.get_feature_names_out()[selected_feature_indices]\n",
    "print('Columns after feature selection: ', selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing accuracy score:\n",
    "acc_sco = accuracy_score(Y_test, model.predict(X_test)) \n",
    "\n",
    "# construction confusion matrix\n",
    "cm = conf_mat(model, Y_test)\n",
    "\n",
    "# store model results in tuned_models dictionary\n",
    "\n",
    "print('Accuracy on the test set: ',acc_sco)\n",
    "tuned_models['KNN'] = {'accuracy': acc_sco, 'model': model, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa573a2b",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic Regression (aka logit, MaxEnt) classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting the timer to see how much time it takes\n",
    "start_time = time.time()\n",
    "\n",
    "# Let's define the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('imputer', KNNImputer()),\n",
    "    #('selector', SelectKBest()),\n",
    "    ('model', LogisticRegression(random_state=2023))\n",
    "])\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    #'selector__k': [5, 10, 20, 40, 60],\n",
    "    'model__penalty': ['l2'],\n",
    "    'model__C': [0.001, 0.01, 0.1, 1.0],\n",
    "    'model__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'model__max_iter': [50, 100, 150, 200, 300],\n",
    "    'model__tol': [0.01, 0.001, 0.0001, 0.00001]\n",
    "}\n",
    "# create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, verbose=2, n_jobs=3)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# evaluate the best model on the test set\n",
    "score = grid_search.score(X_test, Y_test)\n",
    "\n",
    "# stopping the timer and seeing the result: ------------------------\n",
    "end_time = time.time()\n",
    "\n",
    "print('Accuracy on the test set: ', score)\n",
    "print('\\nBest parameters after the grid search: ', grid_search.best_params_)\n",
    "print(\"\\nTime taken for model to learn: \", end_time - start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle\n",
    "if input('Are you sure you want to run this cell? It will overwrite current best model. Y/N: ') == 'Y':\n",
    "    with open('trained_models/best_logistic_regression.pkl', 'wb') as f:\n",
    "        pickle.dump(grid_search, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a13097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model from disk using pickle\n",
    "with open('trained_models/best_logistic_regression.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    " \n",
    "print('Best parameters after the grid search: ', model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected feature indices after SelectKBest() in the best estimator\n",
    "selected_feature_indices = model.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "\n",
    "# Get the column names of the selected features\n",
    "selected_feature_names = preprocessor.get_feature_names_out()[selected_feature_indices]\n",
    "print('Columns after feature selection: ', selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97adb1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing accuracy score:\n",
    "acc_sco = accuracy_score(Y_test, model.predict(X_test)) \n",
    "\n",
    "# construction confusion matrix\n",
    "cm = conf_mat(model, Y_test)\n",
    "\n",
    "# store model results in tuned_models dictionary\n",
    "\n",
    "print('Accuracy on the test set: ',acc_sco)\n",
    "tuned_models['Logistic_Regression'] = {'accuracy': acc_sco, 'model': model, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243ead1",
   "metadata": {},
   "source": [
    "# FINAL TUNEL MODELS COMPARISON\n",
    "\n",
    "Here we assess the performance of each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8221224",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models_acc(tuned_models, naive_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65385da5",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "\n",
    "If the odds are available before the fight, then there is nothing inherently wrong with using them as a predictor. However, it's important to keep in mind that any information used for prediction should be available at the time the prediction is made. If the model is trained on data that includes information (such as odds) that would not be available at the time of prediction, then the model may overfit to the training data and perform poorly on new, unseen data.\n",
    "\n",
    "Additionally, it's important to consider the ethics of using betting odds for predictive modeling. While it may be legal to use this information for research purposes, it could be seen as promoting gambling or taking advantage of vulnerable populations. It's important to approach this type of research with sensitivity and to consider the potential impacts of the research on society."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
